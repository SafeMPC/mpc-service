// Code generated by SQLBoiler 4.19.5 (https://github.com/aarondl/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"bytes"
	"context"
	"reflect"
	"testing"

	"github.com/aarondl/randomize"
	"github.com/aarondl/sqlboiler/v4/boil"
	"github.com/aarondl/sqlboiler/v4/queries"
	"github.com/aarondl/strmangle"
)

var (
	// Relationships sometimes use the reflection helper queries.Equal/queries.Assign
	// so force a package dependency in case they don't.
	_ = queries.Equal
)

func testBackupShareDeliveries(t *testing.T) {
	t.Parallel()

	query := BackupShareDeliveries()

	if query.Query == nil {
		t.Error("expected a query, got nothing")
	}
}

func testBackupShareDeliveriesDelete(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if rowsAff, err := o.Delete(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testBackupShareDeliveriesQueryDeleteAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if rowsAff, err := BackupShareDeliveries().DeleteAll(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testBackupShareDeliveriesSliceDeleteAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice := BackupShareDeliverySlice{o}

	if rowsAff, err := slice.DeleteAll(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testBackupShareDeliveriesExists(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	e, err := BackupShareDeliveryExists(ctx, tx, o.ID)
	if err != nil {
		t.Errorf("Unable to check if BackupShareDelivery exists: %s", err)
	}
	if !e {
		t.Errorf("Expected BackupShareDeliveryExists to return true, but got false.")
	}
}

func testBackupShareDeliveriesFind(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	backupShareDeliveryFound, err := FindBackupShareDelivery(ctx, tx, o.ID)
	if err != nil {
		t.Error(err)
	}

	if backupShareDeliveryFound == nil {
		t.Error("want a record, got nil")
	}
}

func testBackupShareDeliveriesBind(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if err = BackupShareDeliveries().Bind(ctx, tx, o); err != nil {
		t.Error(err)
	}
}

func testBackupShareDeliveriesOne(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if x, err := BackupShareDeliveries().One(ctx, tx); err != nil {
		t.Error(err)
	} else if x == nil {
		t.Error("expected to get a non nil record")
	}
}

func testBackupShareDeliveriesAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	backupShareDeliveryOne := &BackupShareDelivery{}
	backupShareDeliveryTwo := &BackupShareDelivery{}
	if err = randomize.Struct(seed, backupShareDeliveryOne, backupShareDeliveryDBTypes, false, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}
	if err = randomize.Struct(seed, backupShareDeliveryTwo, backupShareDeliveryDBTypes, false, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = backupShareDeliveryOne.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}
	if err = backupShareDeliveryTwo.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice, err := BackupShareDeliveries().All(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if len(slice) != 2 {
		t.Error("want 2 records, got:", len(slice))
	}
}

func testBackupShareDeliveriesCount(t *testing.T) {
	t.Parallel()

	var err error
	seed := randomize.NewSeed()
	backupShareDeliveryOne := &BackupShareDelivery{}
	backupShareDeliveryTwo := &BackupShareDelivery{}
	if err = randomize.Struct(seed, backupShareDeliveryOne, backupShareDeliveryDBTypes, false, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}
	if err = randomize.Struct(seed, backupShareDeliveryTwo, backupShareDeliveryDBTypes, false, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = backupShareDeliveryOne.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}
	if err = backupShareDeliveryTwo.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 2 {
		t.Error("want 2 records, got:", count)
	}
}

func testBackupShareDeliveriesInsert(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}
}

func testBackupShareDeliveriesInsertWhitelist(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Whitelist(strmangle.SetMerge(backupShareDeliveryPrimaryKeyColumns, backupShareDeliveryColumnsWithoutDefault)...)); err != nil {
		t.Error(err)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}
}

func testBackupShareDeliveryToOneKeyUsingKey(t *testing.T) {
	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()

	var local BackupShareDelivery
	var foreign Key

	seed := randomize.NewSeed()
	if err := randomize.Struct(seed, &local, backupShareDeliveryDBTypes, false, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}
	if err := randomize.Struct(seed, &foreign, keyDBTypes, false, keyColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Key struct: %s", err)
	}

	if err := foreign.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	local.KeyID = foreign.KeyID
	if err := local.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	check, err := local.Key().One(ctx, tx)
	if err != nil {
		t.Fatal(err)
	}

	if check.KeyID != foreign.KeyID {
		t.Errorf("want: %v, got %v", foreign.KeyID, check.KeyID)
	}

	slice := BackupShareDeliverySlice{&local}
	if err = local.L.LoadKey(ctx, tx, false, (*[]*BackupShareDelivery)(&slice), nil); err != nil {
		t.Fatal(err)
	}
	if local.R.Key == nil {
		t.Error("struct should have been eager loaded")
	}

	local.R.Key = nil
	if err = local.L.LoadKey(ctx, tx, true, &local, nil); err != nil {
		t.Fatal(err)
	}
	if local.R.Key == nil {
		t.Error("struct should have been eager loaded")
	}

}

func testBackupShareDeliveryToOneSetOpKeyUsingKey(t *testing.T) {
	var err error

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()

	var a BackupShareDelivery
	var b, c Key

	seed := randomize.NewSeed()
	if err = randomize.Struct(seed, &a, backupShareDeliveryDBTypes, false, strmangle.SetComplement(backupShareDeliveryPrimaryKeyColumns, backupShareDeliveryColumnsWithoutDefault)...); err != nil {
		t.Fatal(err)
	}
	if err = randomize.Struct(seed, &b, keyDBTypes, false, strmangle.SetComplement(keyPrimaryKeyColumns, keyColumnsWithoutDefault)...); err != nil {
		t.Fatal(err)
	}
	if err = randomize.Struct(seed, &c, keyDBTypes, false, strmangle.SetComplement(keyPrimaryKeyColumns, keyColumnsWithoutDefault)...); err != nil {
		t.Fatal(err)
	}

	if err := a.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}
	if err = b.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	for i, x := range []*Key{&b, &c} {
		err = a.SetKey(ctx, tx, i != 0, x)
		if err != nil {
			t.Fatal(err)
		}

		if a.R.Key != x {
			t.Error("relationship struct not set to correct value")
		}

		if x.R.BackupShareDeliveries[0] != &a {
			t.Error("failed to append to foreign relationship struct")
		}
		if a.KeyID != x.KeyID {
			t.Error("foreign key was wrong value", a.KeyID)
		}

		zero := reflect.Zero(reflect.TypeOf(a.KeyID))
		reflect.Indirect(reflect.ValueOf(&a.KeyID)).Set(zero)

		if err = a.Reload(ctx, tx); err != nil {
			t.Fatal("failed to reload", err)
		}

		if a.KeyID != x.KeyID {
			t.Error("foreign key was wrong value", a.KeyID, x.KeyID)
		}
	}
}

func testBackupShareDeliveriesReload(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if err = o.Reload(ctx, tx); err != nil {
		t.Error(err)
	}
}

func testBackupShareDeliveriesReloadAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice := BackupShareDeliverySlice{o}

	if err = slice.ReloadAll(ctx, tx); err != nil {
		t.Error(err)
	}
}

func testBackupShareDeliveriesSelect(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice, err := BackupShareDeliveries().All(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if len(slice) != 1 {
		t.Error("want one record, got:", len(slice))
	}
}

var (
	backupShareDeliveryDBTypes = map[string]string{`ID`: `bigint`, `KeyID`: `character varying`, `NodeID`: `character varying`, `UserID`: `character varying`, `ShareIndex`: `integer`, `Status`: `character varying`, `DeliveredAt`: `timestamp with time zone`, `ConfirmedAt`: `timestamp with time zone`, `FailureReason`: `text`, `CreatedAt`: `timestamp with time zone`, `UpdatedAt`: `timestamp with time zone`}
	_                          = bytes.MinRead
)

func testBackupShareDeliveriesUpdate(t *testing.T) {
	t.Parallel()

	if 0 == len(backupShareDeliveryPrimaryKeyColumns) {
		t.Skip("Skipping table with no primary key columns")
	}
	if len(backupShareDeliveryAllColumns) == len(backupShareDeliveryPrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}

	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryPrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	if rowsAff, err := o.Update(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only affect one row but affected", rowsAff)
	}
}

func testBackupShareDeliveriesSliceUpdateAll(t *testing.T) {
	t.Parallel()

	if len(backupShareDeliveryAllColumns) == len(backupShareDeliveryPrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	o := &BackupShareDelivery{}
	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}

	if err = randomize.Struct(seed, o, backupShareDeliveryDBTypes, true, backupShareDeliveryPrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	// Remove Primary keys and unique columns from what we plan to update
	var fields []string
	if strmangle.StringSliceMatch(backupShareDeliveryAllColumns, backupShareDeliveryPrimaryKeyColumns) {
		fields = backupShareDeliveryAllColumns
	} else {
		fields = strmangle.SetComplement(
			backupShareDeliveryAllColumns,
			backupShareDeliveryPrimaryKeyColumns,
		)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	typ := reflect.TypeOf(o).Elem()
	n := typ.NumField()

	updateMap := M{}
	for _, col := range fields {
		for i := 0; i < n; i++ {
			f := typ.Field(i)
			if f.Tag.Get("boil") == col {
				updateMap[col] = value.Field(i).Interface()
			}
		}
	}

	slice := BackupShareDeliverySlice{o}
	if rowsAff, err := slice.UpdateAll(ctx, tx, updateMap); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("wanted one record updated but got", rowsAff)
	}
}

func testBackupShareDeliveriesUpsert(t *testing.T) {
	t.Parallel()

	if len(backupShareDeliveryAllColumns) == len(backupShareDeliveryPrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	// Attempt the INSERT side of an UPSERT
	o := BackupShareDelivery{}
	if err = randomize.Struct(seed, &o, backupShareDeliveryDBTypes, true); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Upsert(ctx, tx, false, nil, boil.Infer(), boil.Infer()); err != nil {
		t.Errorf("Unable to upsert BackupShareDelivery: %s", err)
	}

	count, err := BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}
	if count != 1 {
		t.Error("want one record, got:", count)
	}

	// Attempt the UPDATE side of an UPSERT
	if err = randomize.Struct(seed, &o, backupShareDeliveryDBTypes, false, backupShareDeliveryPrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize BackupShareDelivery struct: %s", err)
	}

	if err = o.Upsert(ctx, tx, true, nil, boil.Infer(), boil.Infer()); err != nil {
		t.Errorf("Unable to upsert BackupShareDelivery: %s", err)
	}

	count, err = BackupShareDeliveries().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}
	if count != 1 {
		t.Error("want one record, got:", count)
	}
}
