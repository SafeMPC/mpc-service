// Code generated by SQLBoiler 4.19.5 (https://github.com/aarondl/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"bytes"
	"context"
	"reflect"
	"testing"

	"github.com/aarondl/randomize"
	"github.com/aarondl/sqlboiler/v4/boil"
	"github.com/aarondl/sqlboiler/v4/queries"
	"github.com/aarondl/strmangle"
)

var (
	// Relationships sometimes use the reflection helper queries.Equal/queries.Assign
	// so force a package dependency in case they don't.
	_ = queries.Equal
)

func testBackupShares(t *testing.T) {
	t.Parallel()

	query := BackupShares()

	if query.Query == nil {
		t.Error("expected a query, got nothing")
	}
}

func testBackupSharesDelete(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if rowsAff, err := o.Delete(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testBackupSharesQueryDeleteAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if rowsAff, err := BackupShares().DeleteAll(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testBackupSharesSliceDeleteAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice := BackupShareSlice{o}

	if rowsAff, err := slice.DeleteAll(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testBackupSharesExists(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	e, err := BackupShareExists(ctx, tx, o.ID)
	if err != nil {
		t.Errorf("Unable to check if BackupShare exists: %s", err)
	}
	if !e {
		t.Errorf("Expected BackupShareExists to return true, but got false.")
	}
}

func testBackupSharesFind(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	backupShareFound, err := FindBackupShare(ctx, tx, o.ID)
	if err != nil {
		t.Error(err)
	}

	if backupShareFound == nil {
		t.Error("want a record, got nil")
	}
}

func testBackupSharesBind(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if err = BackupShares().Bind(ctx, tx, o); err != nil {
		t.Error(err)
	}
}

func testBackupSharesOne(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if x, err := BackupShares().One(ctx, tx); err != nil {
		t.Error(err)
	} else if x == nil {
		t.Error("expected to get a non nil record")
	}
}

func testBackupSharesAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	backupShareOne := &BackupShare{}
	backupShareTwo := &BackupShare{}
	if err = randomize.Struct(seed, backupShareOne, backupShareDBTypes, false, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}
	if err = randomize.Struct(seed, backupShareTwo, backupShareDBTypes, false, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = backupShareOne.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}
	if err = backupShareTwo.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice, err := BackupShares().All(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if len(slice) != 2 {
		t.Error("want 2 records, got:", len(slice))
	}
}

func testBackupSharesCount(t *testing.T) {
	t.Parallel()

	var err error
	seed := randomize.NewSeed()
	backupShareOne := &BackupShare{}
	backupShareTwo := &BackupShare{}
	if err = randomize.Struct(seed, backupShareOne, backupShareDBTypes, false, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}
	if err = randomize.Struct(seed, backupShareTwo, backupShareDBTypes, false, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = backupShareOne.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}
	if err = backupShareTwo.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 2 {
		t.Error("want 2 records, got:", count)
	}
}

func testBackupSharesInsert(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}
}

func testBackupSharesInsertWhitelist(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Whitelist(strmangle.SetMerge(backupSharePrimaryKeyColumns, backupShareColumnsWithoutDefault)...)); err != nil {
		t.Error(err)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}
}

func testBackupShareToOneKeyUsingKey(t *testing.T) {
	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()

	var local BackupShare
	var foreign Key

	seed := randomize.NewSeed()
	if err := randomize.Struct(seed, &local, backupShareDBTypes, false, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}
	if err := randomize.Struct(seed, &foreign, keyDBTypes, false, keyColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Key struct: %s", err)
	}

	if err := foreign.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	local.KeyID = foreign.KeyID
	if err := local.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	check, err := local.Key().One(ctx, tx)
	if err != nil {
		t.Fatal(err)
	}

	if check.KeyID != foreign.KeyID {
		t.Errorf("want: %v, got %v", foreign.KeyID, check.KeyID)
	}

	slice := BackupShareSlice{&local}
	if err = local.L.LoadKey(ctx, tx, false, (*[]*BackupShare)(&slice), nil); err != nil {
		t.Fatal(err)
	}
	if local.R.Key == nil {
		t.Error("struct should have been eager loaded")
	}

	local.R.Key = nil
	if err = local.L.LoadKey(ctx, tx, true, &local, nil); err != nil {
		t.Fatal(err)
	}
	if local.R.Key == nil {
		t.Error("struct should have been eager loaded")
	}

}

func testBackupShareToOneSetOpKeyUsingKey(t *testing.T) {
	var err error

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()

	var a BackupShare
	var b, c Key

	seed := randomize.NewSeed()
	if err = randomize.Struct(seed, &a, backupShareDBTypes, false, strmangle.SetComplement(backupSharePrimaryKeyColumns, backupShareColumnsWithoutDefault)...); err != nil {
		t.Fatal(err)
	}
	if err = randomize.Struct(seed, &b, keyDBTypes, false, strmangle.SetComplement(keyPrimaryKeyColumns, keyColumnsWithoutDefault)...); err != nil {
		t.Fatal(err)
	}
	if err = randomize.Struct(seed, &c, keyDBTypes, false, strmangle.SetComplement(keyPrimaryKeyColumns, keyColumnsWithoutDefault)...); err != nil {
		t.Fatal(err)
	}

	if err := a.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}
	if err = b.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	for i, x := range []*Key{&b, &c} {
		err = a.SetKey(ctx, tx, i != 0, x)
		if err != nil {
			t.Fatal(err)
		}

		if a.R.Key != x {
			t.Error("relationship struct not set to correct value")
		}

		if x.R.BackupShares[0] != &a {
			t.Error("failed to append to foreign relationship struct")
		}
		if a.KeyID != x.KeyID {
			t.Error("foreign key was wrong value", a.KeyID)
		}

		zero := reflect.Zero(reflect.TypeOf(a.KeyID))
		reflect.Indirect(reflect.ValueOf(&a.KeyID)).Set(zero)

		if err = a.Reload(ctx, tx); err != nil {
			t.Fatal("failed to reload", err)
		}

		if a.KeyID != x.KeyID {
			t.Error("foreign key was wrong value", a.KeyID, x.KeyID)
		}
	}
}

func testBackupSharesReload(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if err = o.Reload(ctx, tx); err != nil {
		t.Error(err)
	}
}

func testBackupSharesReloadAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice := BackupShareSlice{o}

	if err = slice.ReloadAll(ctx, tx); err != nil {
		t.Error(err)
	}
}

func testBackupSharesSelect(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice, err := BackupShares().All(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if len(slice) != 1 {
		t.Error("want one record, got:", len(slice))
	}
}

var (
	backupShareDBTypes = map[string]string{`ID`: `bigint`, `KeyID`: `character varying`, `NodeID`: `character varying`, `ShareIndex`: `integer`, `ShareData`: `bytea`, `CreatedAt`: `timestamp with time zone`}
	_                  = bytes.MinRead
)

func testBackupSharesUpdate(t *testing.T) {
	t.Parallel()

	if 0 == len(backupSharePrimaryKeyColumns) {
		t.Skip("Skipping table with no primary key columns")
	}
	if len(backupShareAllColumns) == len(backupSharePrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}

	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupSharePrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	if rowsAff, err := o.Update(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only affect one row but affected", rowsAff)
	}
}

func testBackupSharesSliceUpdateAll(t *testing.T) {
	t.Parallel()

	if len(backupShareAllColumns) == len(backupSharePrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	o := &BackupShare{}
	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupShareColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}

	if err = randomize.Struct(seed, o, backupShareDBTypes, true, backupSharePrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	// Remove Primary keys and unique columns from what we plan to update
	var fields []string
	if strmangle.StringSliceMatch(backupShareAllColumns, backupSharePrimaryKeyColumns) {
		fields = backupShareAllColumns
	} else {
		fields = strmangle.SetComplement(
			backupShareAllColumns,
			backupSharePrimaryKeyColumns,
		)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	typ := reflect.TypeOf(o).Elem()
	n := typ.NumField()

	updateMap := M{}
	for _, col := range fields {
		for i := 0; i < n; i++ {
			f := typ.Field(i)
			if f.Tag.Get("boil") == col {
				updateMap[col] = value.Field(i).Interface()
			}
		}
	}

	slice := BackupShareSlice{o}
	if rowsAff, err := slice.UpdateAll(ctx, tx, updateMap); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("wanted one record updated but got", rowsAff)
	}
}

func testBackupSharesUpsert(t *testing.T) {
	t.Parallel()

	if len(backupShareAllColumns) == len(backupSharePrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	// Attempt the INSERT side of an UPSERT
	o := BackupShare{}
	if err = randomize.Struct(seed, &o, backupShareDBTypes, true); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Upsert(ctx, tx, false, nil, boil.Infer(), boil.Infer()); err != nil {
		t.Errorf("Unable to upsert BackupShare: %s", err)
	}

	count, err := BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}
	if count != 1 {
		t.Error("want one record, got:", count)
	}

	// Attempt the UPDATE side of an UPSERT
	if err = randomize.Struct(seed, &o, backupShareDBTypes, false, backupSharePrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize BackupShare struct: %s", err)
	}

	if err = o.Upsert(ctx, tx, true, nil, boil.Infer(), boil.Infer()); err != nil {
		t.Errorf("Unable to upsert BackupShare: %s", err)
	}

	count, err = BackupShares().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}
	if count != 1 {
		t.Error("want one record, got:", count)
	}
}
